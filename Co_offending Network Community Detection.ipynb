{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import graph_tool as gt\n",
    "from graph_tool import stats, inference, topology\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools as it \n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "co_offending_table = pd.read_csv('./raw_datasets/Cooffending.csv')\n",
    "co_offending_table.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_co_offending_network_from_df(co_offending_df):\n",
    "    offender_ids = np.unique(co_offending_df.NoUnique)\n",
    "    ## Number of verticies is just the number of (unique) offenders\n",
    "    N = len(offender_ids)\n",
    "    g = gt.Graph(directed=False)\n",
    "    g.add_vertex(N)\n",
    "    no_unique = g.new_vertex_property('int')\n",
    "    \n",
    "    print('adding nodes')\n",
    "    \n",
    "    ## Add offenders as nodes and store a mapping from offender_ids\n",
    "    ## to vertex index in the graph\n",
    "    no_unique_to_index = {} \n",
    "    for (i, offender_id) in enumerate(offender_ids):\n",
    "        no_unique[i] = offender_id\n",
    "        no_unique_to_index[offender_id] = i\n",
    "\n",
    "    g.vertex_properties['no_unique'] = no_unique\n",
    "    \n",
    "    print('nodes added')\n",
    "    \n",
    "    ## Add (unweighted) edges between offenders\n",
    "    ## who are arrested together \n",
    "    \n",
    "    print('adding edges')\n",
    "    \n",
    "    edge_iterators = co_offending_df.groupby('SeqE').apply(\n",
    "        lambda x: it.combinations(map(lambda y: no_unique_to_index[y], x.NoUnique.values), 2))   \n",
    "    for iterator in edge_iterators:\n",
    "        for (source, dest) in iterator:\n",
    "            # no self loops\n",
    "            if source == dest:\n",
    "                continue\n",
    "            else:\n",
    "                g.add_edge(source, dest)\n",
    "                g.add_edge(dest, source)\n",
    "    \n",
    "    print('edges added')\n",
    "    \n",
    "    # may have added edges many times so we need to remove parallel edges\n",
    "    gt.stats.remove_parallel_edges(g)\n",
    "    \n",
    "    return(g, no_unique_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_co_offender_network_from_year_range(start_year, end_year, co_offending_table):\n",
    "    filtered_df = co_offending_table[(co_offending_table.annee >= start_year) & \n",
    "                                     (co_offending_table.annee < end_year)]\n",
    "    res = build_co_offending_network_from_df(filtered_df)\n",
    "    return(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Graphs (DO NOT RUN AGAIN - LOAD FROM MEMORY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding nodes\n",
      "nodes added\n",
      "adding edges\n",
      "edges added\n",
      "adding nodes\n",
      "nodes added\n",
      "adding edges\n",
      "edges added\n"
     ]
    }
   ],
   "source": [
    "(g_train, mapping_train) = build_co_offender_network_from_year_range(2003, 2007, co_offending_table)\n",
    "(g_test, mapping_test) = build_co_offender_network_from_year_range(2007, 2012, co_offending_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_train.save('./2003_2007_coffender_graph.gml')\n",
    "g_test.save('./2007_2012_cooffender_graph.gml')\n",
    "pkl.dump( mapping_train, open( \"./2003_2007_coffender_map.p\", \"wb\" ) )\n",
    "pkl.dump( mapping_test, open( \"./2007_2012_coffender_map.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Graphs From Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### LOAD FROM SAVED VALUES \n",
    "g_train = gt.Graph(directed=False)\n",
    "g_test = gt.Graph(directed=False)\n",
    "g_train.load(file_name=\"./2003_2007_coffender_graph.gml\")\n",
    "g_test.load(file_name=\"./2007_2012_cooffender_graph.gml\")\n",
    "mapping_train = pkl.load(open( \"./2003_2007_coffender_map.p\", \"rb\" ) )\n",
    "mapping_test = pkl.load(open( \"./2007_2012_coffender_map.p\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_train.set_vertex_filter(None)\n",
    "g_test.set_vertex_filter(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(311065, 87280, 310434, 92879)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_train.num_vertices(), g_train.num_edges(), g_test.num_vertices(), g_test.num_edges()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## APPROACH 1 - Simply Using the Connected Components as Communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove degree zero nodes from the graph \n",
    "degree_map_train = g_train.degree_property_map('out')\n",
    "filter_map_train = g_train.new_vertex_property('bool')\n",
    "\n",
    "for vertex in g_train.vertices():\n",
    "    if degree_map_train[vertex] > 0:\n",
    "        filter_map_train[vertex] = True\n",
    "    else:\n",
    "        filter_map_train[vertex] = False\n",
    "        \n",
    "g_train.set_vertex_filter(filter_map_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62968, 87280)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_train.num_vertices(), g_train.num_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get components of training graph \n",
    "\n",
    "## Super Simple Approach - Just Use Connected Components \n",
    "component_map_train, hist = gt.topology.label_components(g_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use components from training graph to construct the test graph\n",
    "degree_map_test = g_test.degree_property_map('out')\n",
    "filter_map_test = g_test.new_vertex_property('bool')\n",
    "component_map_test = g_test.new_vertex_property('int')\n",
    "\n",
    "offenders_in_training_graph = set([g_train.vertex_properties['no_unique'][vertex] for \n",
    "                                   vertex in g_train.vertices()])\n",
    "\n",
    "for vertex in g_test.vertices():\n",
    "    co_offender_id = g_test.vertex_properties['no_unique'][vertex]\n",
    "    if degree_map_test[vertex] > 0 and co_offender_id in offenders_in_training_graph:\n",
    "        # if offender is in the training graph \n",
    "        # then we keep in the test graph \n",
    "        # and use the component label \n",
    "        # from the training graph \n",
    "        filter_map_test[vertex] = True\n",
    "        vertex_index_in_training = mapping_train[co_offender_id]\n",
    "        component_map_test[vertex] = component_map_train[vertex_index_in_training]\n",
    "    else:\n",
    "        filter_map_test[vertex] = False\n",
    "        component_map_test[vertex] = -1\n",
    "\n",
    "g_test.vertex_properties['component'] = component_map_test\n",
    "g_test.set_vertex_filter(filter_map_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8417, 5737)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_test.num_vertices(), g_test.num_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2892617389714291"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt.inference.modularity(g_test, g_test.vertex_properties['component'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## APPROACH 2 - Analysis Restricted To The Largest Connected Component "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_train.set_vertex_filter(None)\n",
    "g_test.set_vertex_filter(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Restrict the Training Set To the Largest Component \n",
    "largest_component_train = gt.topology.label_largest_component(g_train)\n",
    "g_train.set_vertex_filter(largest_component_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1459, 6255)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_train.num_vertices(), g_train.num_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    B: 849 <- 1459    shrinking 1459 -> 1122\n",
      "    B: 849 <- 1459    B=1122  niter:     1  count:    0  breaks:  0  min_S: 45327.534  max_S: 45338.414  S: 45327.534  ΔS:     -10.8802  moves:    18 \n",
      "    B: 849 <- 1459    B=1122  niter:     2  count:    1  breaks:  1  min_S: 45327.534  max_S: 45338.414  S: 45325.942  ΔS:     -1.59256  moves:     6 \n",
      "    B: 849 <- 1459    shrinking 1122 -> 863\n",
      "    B: 849 <- 1459    B=863  niter:     1  count:    0  breaks:  0  min_S: 42757.071  max_S: 42793.480  S: 42757.071  ΔS:     -36.4090  moves:    43 \n",
      "    B: 849 <- 1459    B=863  niter:     2  count:    0  breaks:  0  min_S: 42745.884  max_S: 42793.480  S: 42745.884  ΔS:     -11.1869  moves:    14 \n",
      "    B: 849 <- 1459    B=863  niter:     3  count:    1  breaks:  1  min_S: 42745.884  max_S: 42793.480  S: 42743.111  ΔS:     -2.77236  moves:     7 \n",
      "    B: 849 <- 1459    shrinking 863 -> 849\n",
      "    B: 849 <- 1459    B=849  niter:     1  count:    1  breaks:  1  min_S: 42569.467  max_S: 42569.467  S: 42568.774  ΔS:    -0.693147  moves:     2 \n",
      "Current bracket: (1, 849, 1459) (28716.356827877655, 42568.774303894716, 47584.969056744827)\n",
      "    B: 472 <- 849    shrinking 849 -> 653\n",
      "    B: 472 <- 849    B=653  niter:     1  count:    0  breaks:  0  min_S: 39982.050  max_S: 40024.653  S: 39982.050  ΔS:     -42.6031  moves:    55 \n",
      "    B: 472 <- 849    B=653  niter:     2  count:    0  breaks:  0  min_S: 39966.147  max_S: 40024.653  S: 39966.147  ΔS:     -15.9029  moves:    18 \n",
      "    B: 472 <- 849    B=653  niter:     3  count:    1  breaks:  1  min_S: 39966.147  max_S: 40024.653  S: 39963.317  ΔS:     -2.82918  moves:     5 \n",
      "    B: 472 <- 849    shrinking 653 -> 502\n"
     ]
    }
   ],
   "source": [
    "##### RUNS OUT OF MEMORY! :(\n",
    "\n",
    "community_model_train = gt.inference.minimize_blockmodel_dl(g_train,B_max=None, B_min=None, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use components from training graph to construct the test graph\n",
    "degree_map_test = g_test.degree_property_map('out')\n",
    "filter_map_test = g_test.new_vertex_property('bool')\n",
    "component_map_test = g_test.new_vertex_property('int')\n",
    "\n",
    "offenders_in_training_graph = set([g_train.vertex_properties['no_unique'][vertex] for \n",
    "                                   vertex in g_train.vertices()])\n",
    "\n",
    "for vertex in g_test.vertices():\n",
    "    co_offender_id = g_test.vertex_properties['no_unique'][vertex]\n",
    "    if degree_map_test[vertex] > 0 and co_offender_id in offenders_in_training_graph:\n",
    "        # if offender is in the training graph \n",
    "        # then we keep in the test graph \n",
    "        # and use the component label \n",
    "        # from the training graph \n",
    "        filter_map_test[vertex] = True\n",
    "        vertex_index_in_training = mapping_train[co_offender_id]\n",
    "        # Look up component in block model model \n",
    "        component_map_test[vertex] = community_model_train.b[vertex]\n",
    "    else:\n",
    "        filter_map_test[vertex] = False\n",
    "        component_map_test[vertex] = -1\n",
    "\n",
    "g_test.vertex_properties['component'] = component_map_test\n",
    "g_test.set_vertex_filter(filter_map_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt.inference.modularity(g_test, g_test.vertex_properties['component'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
